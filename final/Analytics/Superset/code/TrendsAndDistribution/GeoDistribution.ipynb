{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a09218c-ec67-4ae0-90c0-7eb76c5ffb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 18:04:45 WARN Utils: Your hostname, MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.33 instead (on interface en0)\n",
      "24/12/01 18:04:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/bhland/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/bhland/.ivy2/jars\n",
      "org.apache.hudi#hudi-spark3.5-bundle_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-25373d1c-4ee2-4898-a822-bcc1443ff84f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hudi#hudi-spark3.5-bundle_2.12;0.15.0 in central\n",
      "\tfound org.apache.hive#hive-storage-api;2.8.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.36 in local-m2-cache\n",
      ":: resolution report :: resolve 70ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.hive#hive-storage-api;2.8.1 from central in [default]\n",
      "\torg.apache.hudi#hudi-spark3.5-bundle_2.12;0.15.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 from local-m2-cache in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-25373d1c-4ee2-4898-a822-bcc1443ff84f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/bhland/miniforge3/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 18:04:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/01 18:04:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/12/01 18:04:46 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/12/01 18:04:46 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PatentBranchAnalytics\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hudi:hudi-spark3.5-bundle_2.12:0.15.0\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.hudi.catalog.HoodieCatalog\") \\\n",
    "    .config(\"spark.sql.hive.convertMetastoreParquet\", \"false\") \\\n",
    "    .config(\"spark.sql.parquet.outputTimestampType\", \"TIMESTAMP_MICROS\") \\\n",
    "    .config(\"spark.sql.datetime.java8API.enabled\", \"true\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4920444c-4097-4196-bbf9-22380bdcbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "filtered_patents_input_path = \"../../data_source/filtered_patents\"\n",
    "inventor_data_path = \"../../data_source/preprocessed_data_input/inventor_info\"\n",
    "\n",
    "geo_distribution_table_path = \"file:/Users/bhland/hive/warehouse/dashboard_analytics_results/geo_distribution\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3915b992-69ef-4dcf-993b-7c9f29ecc12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------------------------------------------------------------------------------------------------------------------------+----------+--------------+-----------+-----------+---------+----------------------------------+---------+\n",
      "|patent_type|patent_date|patent_title                                                                                                                   |num_claims|application_id|filing_date|series_code|patent_id|branch                            |code     |\n",
      "+-----------+-----------+-------------------------------------------------------------------------------------------------------------------------------+----------+--------------+-----------+-----------+---------+----------------------------------+---------+\n",
      "|utility    |2018-06-19 |Filler neck closure assembly                                                                                                   |19        |15412444      |2017-01-23 |15         |10000117 |Software Development and Security |G06Q10/00|\n",
      "|utility    |2018-06-19 |Vehicle camera peripheral                                                                                                      |11        |15655054      |2017-07-20 |15         |10000164 |Networking and Distributed Systems|H04W     |\n",
      "|utility    |2018-06-19 |Creatinine biosensor and method of using the same                                                                              |6         |15509067      |2015-09-01 |15         |10000784 |Data Science and Analytics        |B82Y30/00|\n",
      "|utility    |2018-06-19 |Focusing control device, focusing control method, focusing control program, lens device, and imaging device                    |20        |15590019      |2017-05-09 |15         |10001621 |Artificial Intelligence           |G06T     |\n",
      "|utility    |2018-06-19 |Electronic device comprising a wake up module distinct from a core domain                                                      |19        |14852513      |2015-09-12 |14         |10001829 |Artificial Intelligence           |G10L15/22|\n",
      "|utility    |2018-06-19 |Calibration of multiple rigid bodies in a virtual reality system                                                               |20        |15402422      |2017-01-10 |15         |10001834 |Artificial Intelligence           |G06T     |\n",
      "|utility    |2018-06-19 |Gamification platform                                                                                                          |20        |14845953      |2015-09-04 |14         |10001896 |Software Development and Security |G06F3/048|\n",
      "|utility    |2018-06-19 |Information processing apparatus, information processing system, and information processing method                             |9         |15145178      |2016-05-03 |15         |10001934 |Software Development and Security |H04L67/02|\n",
      "|utility    |2018-06-19 |Systems, methods, and devices for handling Wi-Fi and bluetooth audio                                                           |18        |14733169      |2015-06-08 |14         |10001964 |Networking and Distributed Systems|H04W     |\n",
      "|utility    |2018-06-19 |Determining whether a data storage is encrypted                                                                                |9         |15636520      |2017-06-28 |15         |10002083 |Software Development and Security |G06F21/00|\n",
      "|utility    |2018-06-19 |Client computer for updating a database stored on a server via a network                                                       |5         |15202672      |2016-07-06 |15         |10002151 |Data Science and Analytics        |G06F16/27|\n",
      "|utility    |2018-06-19 |System and method for registration in orthopaedic applications                                                                 |4         |14429301      |2013-10-15 |14         |10002227 |Artificial Intelligence           |G06T     |\n",
      "|utility    |2018-06-19 |Moving body tracking method and moving body tracking device                                                                    |18        |15317758      |2015-07-27 |15         |10002289 |Artificial Intelligence           |G06T     |\n",
      "|utility    |2018-06-19 |Systems and methods for predicting transactions                                                                                |26        |15481094      |2017-04-06 |15         |10002322 |Artificial Intelligence           |G06N     |\n",
      "|utility    |2018-06-19 |Systems and methods for point of sale deposits                                                                                 |20        |15899962      |2018-02-20 |15         |10002346 |Software Development and Security |G06Q20/40|\n",
      "|utility    |2018-06-19 |Producing glyph distance fields                                                                                                |36        |13571562      |2012-08-10 |13         |10002448 |Artificial Intelligence           |G06T     |\n",
      "|utility    |2018-06-19 |Image rendering apparatus and method                                                                                           |24        |14321493      |2014-07-01 |14         |10002457 |Artificial Intelligence           |G06T     |\n",
      "|utility    |2018-06-19 |Information processing apparatus, information processing method, and storage medium, for enabling accurate detection of a color|15        |15150236      |2016-05-09 |15         |10002463 |Artificial Intelligence           |G06T     |\n",
      "|utility    |2018-06-19 |Light field light source orientation method for augmented reality and virtual reality and front-end device                     |6         |15381137      |2016-12-16 |15         |10002464 |Artificial Intelligence           |G06T     |\n",
      "|utility    |2018-06-19 |Information signalling for network assisted interference mitigation                                                            |23        |14440337      |2013-12-03 |14         |10003367 |Networking and Distributed Systems|H04W     |\n",
      "+-----------+-----------+-------------------------------------------------------------------------------------------------------------------------------+----------+--------------+-----------+-----------+---------+----------------------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patents_filtered_df = spark.read.parquet(filtered_patents_input_path)\n",
    "patents_filtered_df.show(truncate=False)\n",
    "\n",
    "inventor_df = spark.read.parquet(inventor_data_path)\n",
    "\n",
    "inventor_filtered_df = inventor_df.join(\n",
    "    patents_filtered_df,\n",
    "    inventor_df.patent_id == patents_filtered_df.patent_id, \n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "inventor_filtered_df = inventor_filtered_df.drop(inventor_df['patent_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3fbd771-39ca-4083-8a39-9c0eb638ff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------------------+-----+--------------+------------+\n",
      "|timestamp |branch                            |state|inventor_count|patent_count|\n",
      "+----------+----------------------------------+-----+--------------+------------+\n",
      "|2019-09-01|Data Science and Analytics        |US-NE|1             |1           |\n",
      "|2024-01-01|Networking and Distributed Systems|US-VA|95            |84          |\n",
      "|2016-03-01|Software Development and Security |US-CO|10            |7           |\n",
      "|2022-12-01|Networking and Distributed Systems|US-OR|45            |30          |\n",
      "|1989-11-01|Data Science and Analytics        |US-WA|3             |1           |\n",
      "|2013-09-01|Software Development and Security |US-FL|10            |8           |\n",
      "|2015-11-01|Networking and Distributed Systems|US-NJ|100           |61          |\n",
      "|2016-04-01|Artificial Intelligence           |US-OR|16            |13          |\n",
      "|2011-05-01|Networking and Distributed Systems|US-TX|66            |33          |\n",
      "|2022-04-01|Artificial Intelligence           |US-NJ|83            |55          |\n",
      "|2015-02-01|Data Science and Analytics        |US-PA|7             |6           |\n",
      "|2008-06-01|Networking and Distributed Systems|US-CA|129           |54          |\n",
      "|2020-12-01|Artificial Intelligence           |US-TX|184           |98          |\n",
      "|2007-09-01|Data Science and Analytics        |US-TX|9             |4           |\n",
      "|1988-08-01|Artificial Intelligence           |US-UT|2             |1           |\n",
      "|2013-01-01|Networking and Distributed Systems|US-IL|33            |17          |\n",
      "|2016-03-01|Networking and Distributed Systems|US-NC|72            |38          |\n",
      "|2022-04-01|Data Science and Analytics        |US-MA|20            |11          |\n",
      "|2011-06-01|Networking and Distributed Systems|US-CA|268           |132         |\n",
      "|2014-05-01|Networking and Distributed Systems|US-CO|29            |21          |\n",
      "+----------+----------------------------------+-----+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- year: date (nullable = true)\n",
      " |-- branch: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- inventor_count: integer (nullable = false)\n",
      " |-- patent_count: integer (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:==========================================>              (9 + 3) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------------------------------+-----+--------------+------------+\n",
      "|timestamp          |year      |branch                            |state|inventor_count|patent_count|\n",
      "+-------------------+----------+----------------------------------+-----+--------------+------------+\n",
      "|2019-09-01 00:00:00|2019-09-01|Data Science and Analytics        |US-NE|1             |1           |\n",
      "|2024-01-01 00:00:00|2024-01-01|Networking and Distributed Systems|US-VA|95            |84          |\n",
      "|2016-03-01 00:00:00|2016-03-01|Software Development and Security |US-CO|10            |7           |\n",
      "|2022-12-01 00:00:00|2022-12-01|Networking and Distributed Systems|US-OR|45            |30          |\n",
      "|1989-11-01 00:00:00|1989-11-01|Data Science and Analytics        |US-WA|3             |1           |\n",
      "|2013-09-01 00:00:00|2013-09-01|Software Development and Security |US-FL|10            |8           |\n",
      "|2015-11-01 00:00:00|2015-11-01|Networking and Distributed Systems|US-NJ|100           |61          |\n",
      "|2016-04-01 00:00:00|2016-04-01|Artificial Intelligence           |US-OR|16            |13          |\n",
      "|2011-05-01 00:00:00|2011-05-01|Networking and Distributed Systems|US-TX|66            |33          |\n",
      "|2022-04-01 00:00:00|2022-04-01|Artificial Intelligence           |US-NJ|83            |55          |\n",
      "|2015-02-01 00:00:00|2015-02-01|Data Science and Analytics        |US-PA|7             |6           |\n",
      "|2008-06-01 00:00:00|2008-06-01|Networking and Distributed Systems|US-CA|129           |54          |\n",
      "|2020-12-01 00:00:00|2020-12-01|Artificial Intelligence           |US-TX|184           |98          |\n",
      "|2007-09-01 00:00:00|2007-09-01|Data Science and Analytics        |US-TX|9             |4           |\n",
      "|1988-08-01 00:00:00|1988-08-01|Artificial Intelligence           |US-UT|2             |1           |\n",
      "|2013-01-01 00:00:00|2013-01-01|Networking and Distributed Systems|US-IL|33            |17          |\n",
      "|2016-03-01 00:00:00|2016-03-01|Networking and Distributed Systems|US-NC|72            |38          |\n",
      "|2022-04-01 00:00:00|2022-04-01|Data Science and Analytics        |US-MA|20            |11          |\n",
      "|2011-06-01 00:00:00|2011-06-01|Networking and Distributed Systems|US-CA|268           |132         |\n",
      "|2014-05-01 00:00:00|2014-05-01|Networking and Distributed Systems|US-CO|29            |21          |\n",
      "+-------------------+----------+----------------------------------+-----+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "inventor_df_with_year = inventor_filtered_df.withColumn(\"year\", F.year(\"patent_date\")).withColumn(\"month\", F.month(\"patent_date\")) \n",
    "\n",
    "geo_data = inventor_df_with_year.groupBy(\"year\", \"month\", \"branch\", \"disambig_state\").agg(\n",
    "    F.countDistinct(\"inventor_id\").alias(\"inventor_count\"),  \n",
    "    F.countDistinct(\"patent_id\").alias(\"patent_count\")  \n",
    ")\n",
    "\n",
    "geo_data_df = geo_data.withColumn(\"timestamp\", make_date(col(\"year\"), col(\"month\"), lit(1)))\n",
    "\n",
    "\n",
    "geo_data_df = geo_data_df.drop(\"month\")\n",
    "\n",
    "# Step 2: Select relevant columns\n",
    "geo_distribution = geo_data_df.select(\n",
    "    F.col(\"timestamp\"),\n",
    "    F.col(\"branch\"),\n",
    "    F.concat(F.lit(\"US-\"), F.col(\"disambig_state\")).alias(\"state\"),\n",
    "    F.col(\"inventor_count\"),\n",
    "    F.col(\"patent_count\")\n",
    ")\n",
    "\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "geo_distribution.show(truncate=False)\n",
    "\n",
    "geo_distribution_with_schema = geo_distribution.select(\n",
    "    col(\"timestamp\").cast(TimestampType()),\n",
    "    col(\"timestamp\").alias(\"year\"),\n",
    "    col(\"branch\").cast(StringType()),\n",
    "    col(\"state\").cast(StringType()),\n",
    "    col(\"inventor_count\").cast(IntegerType()),\n",
    "    col(\"patent_count\").cast(IntegerType())\n",
    ")\n",
    "\n",
    "geo_distribution_with_schema.printSchema()\n",
    "geo_distribution_with_schema = geo_distribution_with_schema.na.drop(how=\"any\")\n",
    "geo_distribution_with_schema.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e9beaf-d31f-4d8e-97f0-7d9623cca343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 18:05:09 WARN DFSPropertiesConfiguration: Cannot find HUDI_CONF_DIR, please set it as the dir of hudi-defaults.conf\n",
      "24/12/01 18:05:09 WARN DFSPropertiesConfiguration: Properties file file:/etc/hudi/conf/hudi-defaults.conf not found. Ignoring to load props file\n",
      "24/12/01 18:05:19 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-hbase.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# WARNING: Unable to get Instrumentation. Dynamic Attach failed. You may add this JAR as -javaagent manually, or supply -Djdk.attach.allowAttachSelf\n",
      "# WARNING: Unable to attach Serviceability Agent. Unable to attach even with module exceptions: [org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed., org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed., org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed.]\n",
      "The Geo Distribution results have been successfully written to the hudi table in hive warehouse.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 18:05:22 WARN HoodieSparkSqlWriterInternal: Closing write client\n"
     ]
    }
   ],
   "source": [
    " geo_distribution_hudi_options = {\n",
    "    'hoodie.table.name': 'geo_distribution',\n",
    "    'hoodie.datasource.write.recordkey.field': 'timestamp,branch,state',\n",
    "    'hoodie.datasource.write.precombine.field': \"inventor_count\",\n",
    "    'hoodie.datasource.write.table.name': 'geo_distribution',\n",
    "    'hoodie.datasource.write.table.type': 'COPY_ON_WRITE',\n",
    "    'hoodie.datasource.write.operation': 'insert',\n",
    "    'hoodie.upsert.shuffle.parallelism': 2,\n",
    "    'hoodie.insert.shuffle.parallelism': 2,\n",
    "}\n",
    "geo_distribution_with_schema.write.format(\"org.apache.hudi\").options(**geo_distribution_hudi_options).mode(\"overwrite\").save(geo_distribution_table_path)\n",
    "\n",
    "print(\"The Geo Distribution results have been successfully written to the hudi table in hive warehouse.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1841b79c-b437-4c3e-b2ba-9ec6ce658bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
