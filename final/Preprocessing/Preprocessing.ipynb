{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6a13ec-b2c7-4ccd-9b3a-5141b7ec8663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- application_id: string (nullable = true)\n",
      " |-- patent_id: string (nullable = true)\n",
      " |-- patent_application_type: string (nullable = true)\n",
      " |-- filing_date: date (nullable = true)\n",
      " |-- series_code: string (nullable = true)\n",
      " |-- rule_47_flag: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 8977871\n",
      "+--------------+---------+-----------------------+-----------+-----------+------------+\n",
      "|application_id|patent_id|patent_application_type|filing_date|series_code|rule_47_flag|\n",
      "+--------------+---------+-----------------------+-----------+-----------+------------+\n",
      "|      05497504|  3963197|                     05| 1074-08-14|         05|           0|\n",
      "|      05508062|  3933359|                     05| 1074-09-23|         05|           0|\n",
      "|      05518254|  3941467|                     05| 1074-10-29|         05|           0|\n",
      "|      05518570|  3936670|                     05| 1074-10-29|         05|           0|\n",
      "|      05555245|  4003574|                     05| 1075-03-04|         05|           0|\n",
      "|      05563957|  3937110|                     05| 1075-04-01|         05|           0|\n",
      "|      05564147|  3943740|                     05| 1075-04-01|         05|           0|\n",
      "|      05571931|  3967129|                     05| 1075-04-28|         05|           0|\n",
      "|      05663038|  4049770|                     05| 1076-03-02|         05|           0|\n",
      "|      05865602|  4143614|                     05| 1077-12-29|         05|           0|\n",
      "+--------------+---------+-----------------------+-----------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import re\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Preprocessing\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\").config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "file_path = \"raw_data/g_application.tsv\"\n",
    "\n",
    "application_schema = StructType([\n",
    "    StructField(\"application_id\", StringType(), True), \n",
    "    StructField(\"patent_id\", StringType(), True),      \n",
    "    StructField(\"patent_application_type\", StringType(), True),  \n",
    "    StructField(\"filing_date\", DateType(), True),       \n",
    "    StructField(\"series_code\", StringType(), True),    \n",
    "    StructField(\"rule_47_flag\", IntegerType(), True)    \n",
    "])\n",
    "\n",
    "\n",
    "application_df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").schema(application_schema).csv(file_path)\n",
    "\n",
    "application_df.printSchema()\n",
    "\n",
    "record_count = application_df.count()\n",
    "print(f\"Total number of records: {record_count}\")\n",
    "\n",
    "application_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154cd031-9ca7-486c-baf5-f0e0db30955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_valid_dates(df: DataFrame, date_column: str):\n",
    "    valid_date_pattern = r\"^(19|20)\\d{2}-[0-1]\\d-[0-3]\\d$\"\n",
    "    \n",
    "    invalid_date_df = df.filter(~col(date_column).rlike(valid_date_pattern))\n",
    "    invalid_date_count = invalid_date_df.count()\n",
    "    \n",
    "    valid_date_df = df.filter(col(date_column).rlike(valid_date_pattern))\n",
    "\n",
    "    print(f\"Number of records with incorrect dates: {invalid_date_count}\")\n",
    "    print(\"Top 10 records with valid dates:\")\n",
    "    valid_date_df.show(10)\n",
    "    \n",
    "    return valid_date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da94b95e-a5b3-4278-bb5d-f8b6afc49d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with incorrect dates: 48\n",
      "Top 10 records with valid dates:\n",
      "+--------------+---------+-----------------------+-----------+-----------+------------+\n",
      "|application_id|patent_id|patent_application_type|filing_date|series_code|rule_47_flag|\n",
      "+--------------+---------+-----------------------+-----------+-----------+------------+\n",
      "|      06185782|  D268871|                     06| 1900-09-18|         06|           0|\n",
      "|      07469540|  5180907|                     07| 1901-06-03|         07|           0|\n",
      "|      07720223|  5340165|                     07| 1901-06-21|         07|           0|\n",
      "|      07918107|  5243083|                     07| 1902-07-24|         07|           0|\n",
      "|      07960398|  5298141|                     07| 1903-01-15|         07|           0|\n",
      "|      08012055|  5479042|                     08| 1903-02-01|         08|           0|\n",
      "|      08068932|  5381357|                     08| 1903-05-28|         08|           0|\n",
      "|      08078125|  5484917|                     08| 1903-06-16|         08|           0|\n",
      "|       D008593|  D356729|                      D| 1903-05-19|          D|           0|\n",
      "|      06670322|  4875871|                     06| 1904-11-09|         06|           0|\n",
      "+--------------+---------+-----------------------+-----------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "application_valid_date_df = filter_valid_dates(application_df, \"filing_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16539d6d-08f3-44ca-8a6a-71307042ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df: DataFrame, columns_to_drop: list) -> DataFrame:\n",
    "    \n",
    "    dropped_df = df.drop(*columns_to_drop)\n",
    "    dropped_df.show(10)\n",
    "    return dropped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e1a56e-b73d-4690-b0b3-2a566aecb4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-----------+-----------+\n",
      "|application_id|patent_id|filing_date|series_code|\n",
      "+--------------+---------+-----------+-----------+\n",
      "|      06185782|  D268871| 1900-09-18|         06|\n",
      "|      07469540|  5180907| 1901-06-03|         07|\n",
      "|      07720223|  5340165| 1901-06-21|         07|\n",
      "|      07918107|  5243083| 1902-07-24|         07|\n",
      "|      07960398|  5298141| 1903-01-15|         07|\n",
      "|      08012055|  5479042| 1903-02-01|         08|\n",
      "|      08068932|  5381357| 1903-05-28|         08|\n",
      "|      08078125|  5484917| 1903-06-16|         08|\n",
      "|       D008593|  D356729| 1903-05-19|          D|\n",
      "|      06670322|  4875871| 1904-11-09|         06|\n",
      "+--------------+---------+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\"rule_47_flag\", \"patent_application_type\"]  \n",
    "application_df_dropped = drop_columns(application_valid_date_df, columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f3111fa-707d-459a-a5a7-f0545767f7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- patent_id: string (nullable = true)\n",
      " |-- patent_type: string (nullable = true)\n",
      " |-- patent_date: date (nullable = true)\n",
      " |-- patent_title: string (nullable = true)\n",
      " |-- wipo_kind: string (nullable = true)\n",
      " |-- num_claims: integer (nullable = true)\n",
      " |-- withdrawn: integer (nullable = true)\n",
      " |-- filename: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 8980130\n",
      "+---------+-----------+-----------+--------------------+---------+----------+---------+-------------+\n",
      "|patent_id|patent_type|patent_date|        patent_title|wipo_kind|num_claims|withdrawn|     filename|\n",
      "+---------+-----------+-----------+--------------------+---------+----------+---------+-------------+\n",
      "| 10000000|    utility| 2018-06-19|Coherent LADAR us...|       B2|        20|        0|ipg180619.xml|\n",
      "| 10000001|    utility| 2018-06-19|Injection molding...|       B2|        12|        0|ipg180619.xml|\n",
      "| 10000002|    utility| 2018-06-19|Method for manufa...|       B2|         9|        0|ipg180619.xml|\n",
      "| 10000003|    utility| 2018-06-19|Method for produc...|       B2|        18|        0|ipg180619.xml|\n",
      "| 10000004|    utility| 2018-06-19|Process of obtain...|       B2|         6|        0|ipg180619.xml|\n",
      "| 10000005|    utility| 2018-06-19|Article vacuum fo...|       B2|         4|        0|ipg180619.xml|\n",
      "| 10000006|    utility| 2018-06-19|Thermoforming mol...|       B2|         8|        0|ipg180619.xml|\n",
      "| 10000007|    utility| 2018-06-19|  PEX expanding tool|       B2|        24|        0|ipg180619.xml|\n",
      "| 10000008|    utility| 2018-06-19|Bracelet mold and...|       B2|        11|        0|ipg180619.xml|\n",
      "| 10000009|    utility| 2018-06-19|Sterile environme...|       B2|        21|        0|ipg180619.xml|\n",
      "+---------+-----------+-----------+--------------------+---------+----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "file_path = \"raw_data/g_patent.tsv\"\n",
    "\n",
    "patent_schema = StructType([\n",
    "    StructField(\"patent_id\", StringType(), True),       \n",
    "    StructField(\"patent_type\", StringType(), True),     \n",
    "    StructField(\"patent_date\", DateType(), True),        \n",
    "    StructField(\"patent_title\", StringType(), True),    \n",
    "    StructField(\"wipo_kind\", StringType(), True),        \n",
    "    StructField(\"num_claims\", IntegerType(), True),      \n",
    "    StructField(\"withdrawn\", IntegerType(), True),      \n",
    "    StructField(\"filename\", StringType(), True)         \n",
    "])\n",
    "\n",
    "\n",
    "patent_df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").schema(patent_schema).csv(file_path)\n",
    "patent_df.printSchema()\n",
    "\n",
    "\n",
    "record_count = patent_df.count()\n",
    "print(f\"Total number of records: {record_count}\")\n",
    "\n",
    "patent_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "072aa72a-055b-4485-8856-60bee3d262f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with incorrect dates: 0\n",
      "Top 10 records with valid dates:\n",
      "+---------+-----------+-----------+--------------------+---------+----------+---------+-------------+\n",
      "|patent_id|patent_type|patent_date|        patent_title|wipo_kind|num_claims|withdrawn|     filename|\n",
      "+---------+-----------+-----------+--------------------+---------+----------+---------+-------------+\n",
      "| 10000000|    utility| 2018-06-19|Coherent LADAR us...|       B2|        20|        0|ipg180619.xml|\n",
      "| 10000001|    utility| 2018-06-19|Injection molding...|       B2|        12|        0|ipg180619.xml|\n",
      "| 10000002|    utility| 2018-06-19|Method for manufa...|       B2|         9|        0|ipg180619.xml|\n",
      "| 10000003|    utility| 2018-06-19|Method for produc...|       B2|        18|        0|ipg180619.xml|\n",
      "| 10000004|    utility| 2018-06-19|Process of obtain...|       B2|         6|        0|ipg180619.xml|\n",
      "| 10000005|    utility| 2018-06-19|Article vacuum fo...|       B2|         4|        0|ipg180619.xml|\n",
      "| 10000006|    utility| 2018-06-19|Thermoforming mol...|       B2|         8|        0|ipg180619.xml|\n",
      "| 10000007|    utility| 2018-06-19|  PEX expanding tool|       B2|        24|        0|ipg180619.xml|\n",
      "| 10000008|    utility| 2018-06-19|Bracelet mold and...|       B2|        11|        0|ipg180619.xml|\n",
      "| 10000009|    utility| 2018-06-19|Sterile environme...|       B2|        21|        0|ipg180619.xml|\n",
      "+---------+-----------+-----------+--------------------+---------+----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "patent_valid_date_df = filter_valid_dates(patent_df, \"patent_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb2f3b34-ca31-4165-9b60-cbf20b7a8f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+--------------------+----------+\n",
      "|patent_id|patent_type|patent_date|        patent_title|num_claims|\n",
      "+---------+-----------+-----------+--------------------+----------+\n",
      "| 10000000|    utility| 2018-06-19|Coherent LADAR us...|        20|\n",
      "| 10000001|    utility| 2018-06-19|Injection molding...|        12|\n",
      "| 10000002|    utility| 2018-06-19|Method for manufa...|         9|\n",
      "| 10000003|    utility| 2018-06-19|Method for produc...|        18|\n",
      "| 10000004|    utility| 2018-06-19|Process of obtain...|         6|\n",
      "| 10000005|    utility| 2018-06-19|Article vacuum fo...|         4|\n",
      "| 10000006|    utility| 2018-06-19|Thermoforming mol...|         8|\n",
      "| 10000007|    utility| 2018-06-19|  PEX expanding tool|        24|\n",
      "| 10000008|    utility| 2018-06-19|Bracelet mold and...|        11|\n",
      "| 10000009|    utility| 2018-06-19|Sterile environme...|        21|\n",
      "+---------+-----------+-----------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\"wipo_kind\", \"withdrawn\", \"filename\"]  \n",
    "patent_df_dropped = drop_columns(patent_valid_date_df, columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bc76d6e-705f-42ec-9af0-f0670cd344cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 8977823\n",
      "root\n",
      " |-- patent_id: string (nullable = true)\n",
      " |-- patent_type: string (nullable = true)\n",
      " |-- patent_date: date (nullable = true)\n",
      " |-- patent_title: string (nullable = true)\n",
      " |-- num_claims: integer (nullable = true)\n",
      " |-- application_id: string (nullable = true)\n",
      " |-- filing_date: date (nullable = true)\n",
      " |-- series_code: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+--------------------+----------+--------------+-----------+-----------+\n",
      "|patent_id|patent_type|patent_date|        patent_title|num_claims|application_id|filing_date|series_code|\n",
      "+---------+-----------+-----------+--------------------+----------+--------------+-----------+-----------+\n",
      "| 10000007|    utility| 2018-06-19|  PEX expanding tool|        24|      15178786| 2016-06-10|         15|\n",
      "| 10000016|    utility| 2018-06-19|Film edge sealing...|        22|      15294450| 2016-10-14|         15|\n",
      "| 10000018|    utility| 2018-06-19|Pull tab design f...|        13|      15148543| 2016-05-06|         15|\n",
      "| 10000021|    utility| 2018-06-19|Method for manufa...|         4|      13378475| 2010-06-23|         13|\n",
      "| 10000024|    utility| 2018-06-19|Apparatus and met...|        25|      14588197| 2014-12-31|         14|\n",
      "| 10000036|    utility| 2018-06-19|High kinetic ener...|        20|      14753848| 2015-06-29|         14|\n",
      "| 10000043|    utility| 2018-06-19|Multilayer film f...|        19|      14718215| 2015-05-21|         14|\n",
      "| 10000047|    utility| 2018-06-19|Method for manufa...|        17|      14772389| 2015-05-15|         14|\n",
      "| 10000048|    utility| 2018-06-19|Taping tool havin...|        24|      15174734| 2016-06-06|         15|\n",
      "| 10000050|    utility| 2018-06-19|Method for the ma...|         3|      14110368| 2012-04-03|         14|\n",
      "+---------+-----------+-----------+--------------------+----------+--------------+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "key_column = \"patent_id\"\n",
    "\n",
    "patent_info_joined_df = patent_df_dropped.join(application_df_dropped, patent_df_dropped[key_column] == application_df_dropped[key_column], \"inner\")\n",
    "\n",
    "patent_info_joined_df = patent_info_joined_df.drop(application_df_dropped[key_column])\n",
    "\n",
    "record_count = patent_info_joined_df.count()\n",
    "print(f\"Total number of records: {record_count}\")\n",
    "patent_info_joined_df.printSchema()\n",
    "patent_info_joined_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa4be8c-72b4-47ce-b826-20ec1cdea432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- patent_id: string (nullable = true)\n",
      " |-- cpc_sequence: integer (nullable = true)\n",
      " |-- cpc_section: string (nullable = true)\n",
      " |-- cpc_class: string (nullable = true)\n",
      " |-- cpc_subclass: string (nullable = true)\n",
      " |-- cpc_group: string (nullable = true)\n",
      " |-- cpc_type: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:=======================================>                (17 + 7) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 54914750\n",
      "+---------+------------+-----------+---------+------------+-----------+-----------+\n",
      "|patent_id|cpc_sequence|cpc_section|cpc_class|cpc_subclass|  cpc_group|   cpc_type|\n",
      "+---------+------------+-----------+---------+------------+-----------+-----------+\n",
      "|  3950000|           0|          A|      A63|        A63C|  A63C9/001|inventional|\n",
      "|  3950000|           1|          A|      A63|        A63C|   A63C9/00|inventional|\n",
      "|  3950000|           2|          A|      A63|        A63C|  A63C9/002|inventional|\n",
      "|  3950000|           3|          A|      A63|        A63C|  A63C9/081|inventional|\n",
      "|  3950001|           0|          A|      A63|        A63C|  A63C9/086|inventional|\n",
      "|  3950001|           1|          A|      A63|        A63C|  A63C9/005|inventional|\n",
      "|  3950001|           2|          A|      A63|        A63C|  A63C9/003| additional|\n",
      "|  3950002|           0|          A|      A63|        A63C|  A63C9/001|inventional|\n",
      "|  3950002|           1|          A|      A63|        A63C|A63C9/08521|inventional|\n",
      "|  3950002|           2|          A|      A63|        A63C|A63C9/08564|inventional|\n",
      "+---------+------------+-----------+---------+------------+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "file_path = \"raw_data/g_cpc_current.tsv\"\n",
    "\n",
    "cpc_schema = StructType([\n",
    "    StructField(\"patent_id\", StringType(), True),          \n",
    "    StructField(\"cpc_sequence\", IntegerType(), True),     \n",
    "    StructField(\"cpc_section\", StringType(), True),       \n",
    "    StructField(\"cpc_class\", StringType(), True),          \n",
    "    StructField(\"cpc_subclass\", StringType(), True),      \n",
    "    StructField(\"cpc_group\", StringType(), True),          \n",
    "    StructField(\"cpc_type\", StringType(), True)            \n",
    "])\n",
    "\n",
    "\n",
    "cpc_df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").schema(cpc_schema).csv(file_path)\n",
    "cpc_df.printSchema()\n",
    "\n",
    "record_count = cpc_df.count()\n",
    "print(f\"Total number of records: {record_count}\")\n",
    "\n",
    "cpc_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d7751fb-0d3e-43ad-aa52-295635aeb5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cpc_subclass: string (nullable = true)\n",
      " |-- cpc_subclass_title: string (nullable = true)\n",
      " |-- cpc_group: string (nullable = true)\n",
      " |-- cpc_group_title: string (nullable = true)\n",
      " |-- cpc_class: string (nullable = true)\n",
      " |-- cpc_class_title: string (nullable = true)\n",
      "\n",
      "Total number of records: 267350\n",
      "+------------+--------------------+---------+--------------------+---------+--------------------+\n",
      "|cpc_subclass|  cpc_subclass_title|cpc_group|     cpc_group_title|cpc_class|     cpc_class_title|\n",
      "+------------+--------------------+---------+--------------------+---------+--------------------+\n",
      "|        A01B|SOIL WORKING IN A...| A01B1/00|         Hand tools |      A01|AGRICULTURE; FORE...|\n",
      "|        A01B|SOIL WORKING IN A...| A01B1/02|Hand tools -Spade...|      A01|AGRICULTURE; FORE...|\n",
      "|        A01B|SOIL WORKING IN A...|A01B1/022|Hand tools -Spade...|      A01|AGRICULTURE; FORE...|\n",
      "|        A01B|SOIL WORKING IN A...|A01B1/024|Hand tools -Spade...|      A01|AGRICULTURE; FORE...|\n",
      "|        A01B|SOIL WORKING IN A...|A01B1/026|Hand tools -Spade...|      A01|AGRICULTURE; FORE...|\n",
      "|        A01B|SOIL WORKING IN A...|A01B1/028|Hand tools -Spade...|      A01|AGRICULTURE; FORE...|\n",
      "|        A01B|SOIL WORKING IN A...| A01B1/04|Hand tools -Spade...|      A01|AGRICULTURE; FORE...|\n",
      "|        A01B|SOIL WORKING IN A...| A01B1/06|Hand tools -Hoes;...|      A01|AGRICULTURE; FORE...|\n",
      "|        A01B|SOIL WORKING IN A...|A01B1/065|Hand tools -Hoes;...|      A01|AGRICULTURE; FORE...|\n",
      "|        A01B|SOIL WORKING IN A...| A01B1/08|Hand tools -Hoes;...|      A01|AGRICULTURE; FORE...|\n",
      "+------------+--------------------+---------+--------------------+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/g_cpc_title.tsv\"\n",
    "\n",
    "cpc_title_schema = StructType([\n",
    "    StructField(\"cpc_subclass\", StringType(), True),         \n",
    "    StructField(\"cpc_subclass_title\", StringType(), True),    \n",
    "    StructField(\"cpc_group\", StringType(), True),             \n",
    "    StructField(\"cpc_group_title\", StringType(), True),      \n",
    "    StructField(\"cpc_class\", StringType(), True),            \n",
    "    StructField(\"cpc_class_title\", StringType(), True)        \n",
    "])\n",
    "\n",
    "\n",
    "cpc_title_df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").schema(cpc_title_schema).csv(file_path)\n",
    "cpc_title_df.printSchema()\n",
    "\n",
    "record_count = cpc_title_df.count()\n",
    "print(f\"Total number of records: {record_count}\")\n",
    "\n",
    "cpc_title_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91e6bb30-18b5-44f2-a801-f5930e4127bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------------------------------------------------------------+\n",
      "|cpc_section|section_description                                                          |\n",
      "+-----------+-----------------------------------------------------------------------------+\n",
      "|A          |Human Necessities                                                            |\n",
      "|B          |Performing Operations; Transporting                                          |\n",
      "|C          |Chemistry; Metallurgy                                                        |\n",
      "|D          |Textiles; Paper                                                              |\n",
      "|E          |Fixed Constructions                                                          |\n",
      "|F          |Mechanical Engineering; Lighting; Heating; Weapons; Blasting Engines or Pumps|\n",
      "|G          |Physics                                                                      |\n",
      "|H          |Electricity                                                                  |\n",
      "|Y          |General Tagging of New Technological Developments                            |\n",
      "+-----------+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"cpc_section\", StringType(), True),\n",
    "    StructField(\"section_description\", StringType(), True)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    (\"A\", \"Human Necessities\"),\n",
    "    (\"B\", \"Performing Operations; Transporting\"),\n",
    "    (\"C\", \"Chemistry; Metallurgy\"),\n",
    "    (\"D\", \"Textiles; Paper\"),\n",
    "    (\"E\", \"Fixed Constructions\"),\n",
    "    (\"F\", \"Mechanical Engineering; Lighting; Heating; Weapons; Blasting Engines or Pumps\"),\n",
    "    (\"G\", \"Physics\"),\n",
    "    (\"H\", \"Electricity\"),\n",
    "    (\"Y\", \"General Tagging of New Technological Developments\")\n",
    "]\n",
    "\n",
    "cpc_section_df = spark.createDataFrame(data, schema)\n",
    "\n",
    "cpc_section_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aef9dce6-c40e-477e-94b2-de177c120d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique CPC Groups:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|    cpc_group|     cpc_group_title|\n",
      "+-------------+--------------------+\n",
      "|    A01B33/14|Tilling implement...|\n",
      "|   A01C23/007|Distributing devi...|\n",
      "|    A01D11/02|Other hand implem...|\n",
      "|   A01D34/015|Mowers ; Mowing a...|\n",
      "|    A01D43/07|Mowers combined w...|\n",
      "|    A01D46/26|Picking of fruits...|\n",
      "|    A01D65/02|Grain-crop lifter...|\n",
      "|   A01D75/246|Accessories for h...|\n",
      "|A01F2015/0891|Baling presses fo...|\n",
      "|    A01G17/02|Cultivation of ho...|\n",
      "+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Unique CPC Subclasses:\n",
      "+------------+--------------------+\n",
      "|cpc_subclass|  cpc_subclass_title|\n",
      "+------------+--------------------+\n",
      "|        A01J|MANUFACTURE OF DA...|\n",
      "|        A23F|COFFEE; TEA; THEI...|\n",
      "|        A61C|DENTISTRY; APPARA...|\n",
      "|        A61K|PREPARATIONS FOR ...|\n",
      "|        B01D|         SEPARATION |\n",
      "|        A44B|BUTTONS, PINS, BU...|\n",
      "|        A63J|DEVICES FOR THEAT...|\n",
      "|        A22C|PROCESSING MEAT, ...|\n",
      "|        A01F|PROCESSING OF HAR...|\n",
      "|        A01N|PRESERVATION OF B...|\n",
      "+------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Unique CPC Classes:\n",
      "+---------+--------------------+\n",
      "|cpc_class|     cpc_class_title|\n",
      "+---------+--------------------+\n",
      "|      A46|           BRUSHWARE|\n",
      "|      A43|            FOOTWEAR|\n",
      "|      A41|     WEARING APPAREL|\n",
      "|      A47|FURNITURE; DOMEST...|\n",
      "|      A21|BAKING; EDIBLE DO...|\n",
      "|      A22|BUTCHERING; MEAT ...|\n",
      "|      A99|SUBJECT MATTER NO...|\n",
      "|      A63|SPORTS; GAMES; AM...|\n",
      "|      A61|MEDICAL OR VETERI...|\n",
      "|      A45|HAND OR TRAVELLIN...|\n",
      "+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cpc_group_df = cpc_title_df.select(\"cpc_group\", \"cpc_group_title\").distinct()\n",
    "\n",
    "cpc_subclass_df = cpc_title_df.select(\"cpc_subclass\", \"cpc_subclass_title\").distinct()\n",
    "\n",
    "cpc_class_df = cpc_title_df.select(\"cpc_class\", \"cpc_class_title\").distinct()\n",
    "\n",
    "print(\"Unique CPC Groups:\")\n",
    "cpc_group_df.show(10)\n",
    "\n",
    "print(\"Unique CPC Subclasses:\")\n",
    "cpc_subclass_df.show(10)\n",
    "\n",
    "print(\"Unique CPC Classes:\")\n",
    "cpc_class_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c8431d6-7abf-4b65-9913-3355b73cf298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- patent_id: string (nullable = true)\n",
      " |-- inventor_sequence: integer (nullable = true)\n",
      " |-- inventor_id: string (nullable = true)\n",
      " |-- disambig_inventor_name_first: string (nullable = true)\n",
      " |-- disambig_inventor_name_last: string (nullable = true)\n",
      " |-- gender_code: string (nullable = true)\n",
      " |-- location_id: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:==========================>                              (8 + 8) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 22595784\n",
      "+---------+-----------------+--------------------+----------------------------+---------------------------+-----------+--------------------+\n",
      "|patent_id|inventor_sequence|         inventor_id|disambig_inventor_name_first|disambig_inventor_name_last|gender_code|         location_id|\n",
      "+---------+-----------------+--------------------+----------------------------+---------------------------+-----------+--------------------+\n",
      "| D1006496|                0|  fl:we_ln:jiang-128|                     Wenjing|                      Jiang|          F|9d072d42-49af-11e...|\n",
      "| 12029253|                4|  fl:ei_ln:baumker-1|                        Eiko|                    BÄUMKER|          M|67149e17-49af-11e...|\n",
      "|  6584128|                0|  fl:ri_ln:kroeger-1|                     Richard|                    Kroeger|          M|                NULL|\n",
      "|  4789863|                0|     fl:th_ln:bush-1|                   Thomas A.|                       Bush|          M|                NULL|\n",
      "| 11161990|                1|fl:ma_ln:boudreaux-4|                  Matthew F.|                  Boudreaux|          M|04726932-16c8-11e...|\n",
      "|  6795487|                1|fl:ge_ln:whitworth-1|                      Gerald|                  Whitworth|          M|                NULL|\n",
      "|  D474886|                0|  fl:th_ln:fleming-4|                   Thomas W.|                    Fleming|          M|1893009c-16c8-11e...|\n",
      "| 11885288|                3|     fl:du_ln:moon-7|                     Duck Su|                       Moon|          F|75f07306-16c8-11e...|\n",
      "|  7646155|                0|    fl:sa_ln:woods-2|                   Samuel G.|                      Woods|          M|fdbaa08c-16c7-11e...|\n",
      "|  4339721|                1|   fl:ta_ln:hosoda-5|                      Takuya|                     Hosoda|          M|42f90495-16c8-11e...|\n",
      "+---------+-----------------+--------------------+----------------------------+---------------------------+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "file_path = \"raw_data/g_inventor_disambiguated.tsv\"\n",
    "\n",
    "inventor_schema = StructType([\n",
    "    StructField(\"patent_id\", StringType(), True),                     \n",
    "    StructField(\"inventor_sequence\", IntegerType(), True),            \n",
    "    StructField(\"inventor_id\", StringType(), True),                    \n",
    "    StructField(\"disambig_inventor_name_first\", StringType(), True),  \n",
    "    StructField(\"disambig_inventor_name_last\", StringType(), True),   \n",
    "    StructField(\"gender_code\", StringType(), True),                    \n",
    "    StructField(\"location_id\", StringType(), True)                    \n",
    "])\n",
    "\n",
    "inventor_df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").schema(inventor_schema).csv(file_path)\n",
    "inventor_df.printSchema()\n",
    "\n",
    "record_count = inventor_df.count()\n",
    "print(f\"Total number of records: {record_count}\")\n",
    "\n",
    "inventor_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1be0b03-bb65-481c-972e-92e42c0a1daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- location_id: string (nullable = true)\n",
      " |-- disambig_city: string (nullable = true)\n",
      " |-- disambig_state: string (nullable = true)\n",
      " |-- disambig_country: string (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- state_fips: string (nullable = true)\n",
      " |-- county_fips: string (nullable = true)\n",
      "\n",
      "Total number of records: 96039\n",
      "+--------------------+---------------+--------------+----------------+---------+----------+-------------------+----------+-----------+\n",
      "|         location_id|  disambig_city|disambig_state|disambig_country| latitude| longitude|             county|state_fips|county_fips|\n",
      "+--------------------+---------------+--------------+----------------+---------+----------+-------------------+----------+-----------+\n",
      "|00235947-16c8-11e...|      Westfield|            PA|              US|41.919235| -77.53887|              Tioga|        42|        117|\n",
      "|00236a27-16c8-11e...|    Helfenstein|            PA|              US|  40.7505|-76.447334|  Schuylkill County|        42|        107|\n",
      "|00236f47-16c8-11e...|     Pine Forge|            PA|              US| 40.28192| -75.69224|       Berks County|        42|        011|\n",
      "|00237418-16c8-11e...|        Partlow|            VA|              US| 38.03875| -77.63888|Spotsylvania County|        51|        177|\n",
      "|002378d7-16c8-11e...|   Stumpy Point|            NC|              US|35.698505|-75.740456|               Dare|        37|        055|\n",
      "|00238cb7-16c8-11e...|        Millers|            MD|              US|39.671215| -76.85109|     Carroll County|        24|        013|\n",
      "|00239181-16c8-11e...|Chester Heights|            PA|              US| 39.89011| -75.47548|           Delaware|        42|        045|\n",
      "|002395ca-16c8-11e...|           Home|            PA|              US| 40.73951|-79.105316|     Indiana County|        42|        063|\n",
      "|002399e0-16c8-11e...|         Taylor|            NY|              US|42.567013| -75.89325|    Cortland County|        36|        023|\n",
      "|00239f81-16c8-11e...|   Willseyville|            NY|              US|42.290073| -76.37827|       Tioga County|        36|        107|\n",
      "+--------------------+---------------+--------------+----------------+---------+----------+-------------------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"raw_data/g_location_disambiguated.tsv\"\n",
    "\n",
    "location_schema = StructType([\n",
    "    StructField(\"location_id\", StringType(), True),                \n",
    "    StructField(\"disambig_city\", StringType(), True),             \n",
    "    StructField(\"disambig_state\", StringType(), True),             \n",
    "    StructField(\"disambig_country\", StringType(), True),          \n",
    "    StructField(\"latitude\", FloatType(), True),                    \n",
    "    StructField(\"longitude\", FloatType(), True),                   \n",
    "    StructField(\"county\", StringType(), True),                     \n",
    "    StructField(\"state_fips\", StringType(), True),               \n",
    "    StructField(\"county_fips\", StringType(), True)                \n",
    "])\n",
    "\n",
    "location_df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").schema(location_schema).csv(file_path)\n",
    "location_df.printSchema()\n",
    "\n",
    "record_count = location_df.count()\n",
    "print(f\"Total number of records: {record_count}\")\n",
    "\n",
    "location_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9020f8a8-f94e-46c4-878f-5365255518fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------+----------------+---------+----------+-------------------+\n",
      "|         location_id|  disambig_city|disambig_state|disambig_country| latitude| longitude|             county|\n",
      "+--------------------+---------------+--------------+----------------+---------+----------+-------------------+\n",
      "|00235947-16c8-11e...|      Westfield|            PA|              US|41.919235| -77.53887|              Tioga|\n",
      "|00236a27-16c8-11e...|    Helfenstein|            PA|              US|  40.7505|-76.447334|  Schuylkill County|\n",
      "|00236f47-16c8-11e...|     Pine Forge|            PA|              US| 40.28192| -75.69224|       Berks County|\n",
      "|00237418-16c8-11e...|        Partlow|            VA|              US| 38.03875| -77.63888|Spotsylvania County|\n",
      "|002378d7-16c8-11e...|   Stumpy Point|            NC|              US|35.698505|-75.740456|               Dare|\n",
      "|00238cb7-16c8-11e...|        Millers|            MD|              US|39.671215| -76.85109|     Carroll County|\n",
      "|00239181-16c8-11e...|Chester Heights|            PA|              US| 39.89011| -75.47548|           Delaware|\n",
      "|002395ca-16c8-11e...|           Home|            PA|              US| 40.73951|-79.105316|     Indiana County|\n",
      "|002399e0-16c8-11e...|         Taylor|            NY|              US|42.567013| -75.89325|    Cortland County|\n",
      "|00239f81-16c8-11e...|   Willseyville|            NY|              US|42.290073| -76.37827|       Tioga County|\n",
      "+--------------------+---------------+--------------+----------------+---------+----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\"state_fips\", \"county_fips\"]  \n",
    "location_df_dropped = drop_columns(location_df, columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb4fbe35-c9fb-4f50-a2da-4101cd88fff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- patent_id: string (nullable = true)\n",
      " |-- inventor_sequence: integer (nullable = true)\n",
      " |-- inventor_id: string (nullable = true)\n",
      " |-- disambig_inventor_name_first: string (nullable = true)\n",
      " |-- disambig_inventor_name_last: string (nullable = true)\n",
      " |-- gender_code: string (nullable = true)\n",
      " |-- location_id: string (nullable = true)\n",
      " |-- disambig_city: string (nullable = true)\n",
      " |-- disambig_state: string (nullable = true)\n",
      " |-- disambig_country: string (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 22595784\n",
      "+---------+-----------------+--------------------+----------------------------+---------------------------+-----------+--------------------+---------------+--------------+----------------+---------+----------+---------+\n",
      "|patent_id|inventor_sequence|         inventor_id|disambig_inventor_name_first|disambig_inventor_name_last|gender_code|         location_id|  disambig_city|disambig_state|disambig_country| latitude| longitude|   county|\n",
      "+---------+-----------------+--------------------+----------------------------+---------------------------+-----------+--------------------+---------------+--------------+----------------+---------+----------+---------+\n",
      "| D1006496|                0|  fl:we_ln:jiang-128|                     Wenjing|                      Jiang|          F|9d072d42-49af-11e...|        Guizhou|          NULL|              CN|30.987291|110.713524|     NULL|\n",
      "| 12029253|                4|  fl:ei_ln:baumker-1|                        Eiko|                    BÄUMKER|          M|67149e17-49af-11e...|Freiburg (Elbe)|          NULL|              DE| 53.82525|   9.28872|     NULL|\n",
      "|  6584128|                0|  fl:ri_ln:kroeger-1|                     Richard|                    Kroeger|          M|                NULL|           NULL|          NULL|            NULL|     NULL|      NULL|     NULL|\n",
      "|  4789863|                0|     fl:th_ln:bush-1|                   Thomas A.|                       Bush|          M|                NULL|           NULL|          NULL|            NULL|     NULL|      NULL|     NULL|\n",
      "| 11161990|                1|fl:ma_ln:boudreaux-4|                  Matthew F.|                  Boudreaux|          M|04726932-16c8-11e...|        Raleigh|            NC|              US|  35.7804|  -78.6391|     Wake|\n",
      "|  6795487|                1|fl:ge_ln:whitworth-1|                      Gerald|                  Whitworth|          M|                NULL|           NULL|          NULL|            NULL|     NULL|      NULL|     NULL|\n",
      "|  D474886|                0|  fl:th_ln:fleming-4|                   Thomas W.|                    Fleming|          M|1893009c-16c8-11e...|      San Diego|            CA|              US| 32.71742|-117.16277|San Diego|\n",
      "| 11885288|                3|     fl:du_ln:moon-7|                     Duck Su|                       Moon|          F|75f07306-16c8-11e...|        Asan-si|          NULL|              KR| 36.78995| 127.00268|     NULL|\n",
      "|  7646155|                0|    fl:sa_ln:woods-2|                   Samuel G.|                      Woods|          M|fdbaa08c-16c7-11e...|        Bel Air|            MD|              US|39.535507| -76.34904|  Harford|\n",
      "|  4339721|                1|   fl:ta_ln:hosoda-5|                      Takuya|                     Hosoda|          M|42f90495-16c8-11e...|          Tokyo|          NULL|              JP| 35.68284| 139.75946|     NULL|\n",
      "+---------+-----------------+--------------------+----------------------------+---------------------------+-----------+--------------------+---------------+--------------+----------------+---------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key_column = \"location_id\"\n",
    "\n",
    "joined_df_inventor = inventor_df.join(location_df_dropped, inventor_df[key_column] == location_df_dropped[key_column], \"left\")\n",
    "\n",
    "joined_df_inventor = joined_df_inventor.drop(location_df_dropped[key_column])\n",
    "\n",
    "joined_df_inventor.printSchema()\n",
    "record_count = joined_df_inventor.count()\n",
    "print(f\"Total number of records: {record_count}\")\n",
    "joined_df_inventor.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc4c0acc-539d-4701-85f7-3b7072f3c653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- patent_id: string (nullable = true)\n",
      " |-- applicant_sequence: integer (nullable = true)\n",
      " |-- raw_applicant_name_first: string (nullable = true)\n",
      " |-- raw_applicant_name_last: string (nullable = true)\n",
      " |-- raw_applicant_organization: string (nullable = true)\n",
      " |-- applicant_type: string (nullable = true)\n",
      " |-- applicant_designation: string (nullable = true)\n",
      " |-- applicant_authority: string (nullable = true)\n",
      " |-- rawlocation_id: string (nullable = true)\n",
      "\n",
      "Total number of records: 5908224\n",
      "+---------+------------------+------------------------+-----------------------+--------------------------+--------------+---------------------+-------------------+--------------------+\n",
      "|patent_id|applicant_sequence|raw_applicant_name_first|raw_applicant_name_last|raw_applicant_organization|applicant_type|applicant_designation|applicant_authority|      rawlocation_id|\n",
      "+---------+------------------+------------------------+-----------------------+--------------------------+--------------+---------------------+-------------------+--------------------+\n",
      "|  9069405|                 3|                   David|                 Bordui|                      NULL|     applicant|              us-only|               NULL|emcq5f1g8kprye06o...|\n",
      "|  9117193|                 6|                James W.|                 Seaman|                      NULL|     applicant|              us-only|               NULL|fa4w8lgydmaocda6g...|\n",
      "|  9764256|                 2|          Terence Arthur|                 Devlin|                      NULL|     applicant|              us-only|               NULL|4pwy4ca2zmjod52ex...|\n",
      "| 10947428|                 1|                    NULL|                   NULL|      PPG Industries Oh...|     applicant|              us-only| obligated-assignee|tkwrlo9614r87fa2f...|\n",
      "| 11212562|                 1|                    NULL|                   NULL|      Amazon Technologi...|     applicant|              us-only|           assignee|csjl4jp4tpws94s01...|\n",
      "| 10188493|                 2|                    Mark|                 Jessup|                      NULL|     applicant|              us-only|               NULL|fd8p8j7616ap84gm2...|\n",
      "| 10791328|                 1|                    NULL|                   NULL|          SONY CORPORATION|     applicant|              us-only|           assignee|rimosb6io67fxvnv2...|\n",
      "|  D820767|                 1|                    NULL|                   NULL|      Tractor Supply Co...|     applicant|              us-only| obligated-assignee|8dhpbelci2nw58juu...|\n",
      "|  8416340|                 1|                     Dai|               Shintani|                      NULL|     applicant|              us-only|               NULL|z9hyc9bl0mrz3lxks...|\n",
      "| 11775485|                 1|                    NULL|                   NULL|            Cohesity, Inc.|     applicant|              us-only|           assignee|g7fpkf8hqtr2nab0a...|\n",
      "+---------+------------------+------------------------+-----------------------+--------------------------+--------------+---------------------+-------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "file_path = \"raw_data/g_applicant_not_disambiguated.tsv\"\n",
    "\n",
    "applicant_schema = StructType([\n",
    "    StructField(\"patent_id\", StringType(), True),                     \n",
    "    StructField(\"applicant_sequence\", IntegerType(), True),           \n",
    "    StructField(\"raw_applicant_name_first\", StringType(), True),       \n",
    "    StructField(\"raw_applicant_name_last\", StringType(), True),        \n",
    "    StructField(\"raw_applicant_organization\", StringType(), True),     \n",
    "    StructField(\"applicant_type\", StringType(), True),                \n",
    "    StructField(\"applicant_designation\", StringType(), True),          \n",
    "    StructField(\"applicant_authority\", StringType(), True),            \n",
    "    StructField(\"rawlocation_id\", StringType(), True)                 \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "applicant_df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").schema(applicant_schema).csv(file_path)\n",
    "applicant_df.printSchema()\n",
    "\n",
    "record_count = applicant_df.count()\n",
    "print(f\"Total number of records: {record_count}\")\n",
    "\n",
    "applicant_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad510809-f239-40c8-9a7c-c757577d96cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------------------+-----------------------+--------------------------+--------------+\n",
      "|patent_id|applicant_sequence|raw_applicant_name_first|raw_applicant_name_last|raw_applicant_organization|applicant_type|\n",
      "+---------+------------------+------------------------+-----------------------+--------------------------+--------------+\n",
      "|  9069405|                 3|                   David|                 Bordui|                      NULL|     applicant|\n",
      "|  9117193|                 6|                James W.|                 Seaman|                      NULL|     applicant|\n",
      "|  9764256|                 2|          Terence Arthur|                 Devlin|                      NULL|     applicant|\n",
      "| 10947428|                 1|                    NULL|                   NULL|      PPG Industries Oh...|     applicant|\n",
      "| 11212562|                 1|                    NULL|                   NULL|      Amazon Technologi...|     applicant|\n",
      "| 10188493|                 2|                    Mark|                 Jessup|                      NULL|     applicant|\n",
      "| 10791328|                 1|                    NULL|                   NULL|          SONY CORPORATION|     applicant|\n",
      "|  D820767|                 1|                    NULL|                   NULL|      Tractor Supply Co...|     applicant|\n",
      "|  8416340|                 1|                     Dai|               Shintani|                      NULL|     applicant|\n",
      "| 11775485|                 1|                    NULL|                   NULL|            Cohesity, Inc.|     applicant|\n",
      "+---------+------------------+------------------------+-----------------------+--------------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\"applicant_authority\", \"rawlocation_id\", \"applicant_designation\"]  \n",
    "applicant_df_dropped = drop_columns(applicant_df, columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6800613a-ef34-4a46-9034-dd6c836d1cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'patent_info' saved successfully to output_parquet_schema/patent_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'cpc_info' saved successfully to output_parquet_schema/cpc_info\n",
      "DataFrame 'cpc_section' saved successfully to output_parquet_schema/cpc_section\n",
      "DataFrame 'cpc_group' saved successfully to output_parquet_schema/cpc_group\n",
      "DataFrame 'cpc_subclass' saved successfully to output_parquet_schema/cpc_subclass\n",
      "DataFrame 'cpc_class' saved successfully to output_parquet_schema/cpc_class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'inventor_info' saved successfully to output_parquet_schema/inventor_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 110:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'applicant_info' saved successfully to output_parquet_schema/applicant_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/23 11:07:13 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1006990 ms exceeds timeout 120000 ms\n",
      "24/11/23 11:07:13 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "24/11/23 11:15:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.0.33:55405\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/11/23 11:15:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.0.33:55405\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    }
   ],
   "source": [
    "def save_dfs_as_parquet_with_names(dfs, directory_path, df_names):\n",
    "    \n",
    "    for df, df_name in zip(dfs, df_names):\n",
    "        file_path = f\"{directory_path}/{df_name}\"\n",
    "        \n",
    "        try:\n",
    "            df.write.parquet(file_path, mode=\"overwrite\")\n",
    "            print(f\"DataFrame '{df_name}' saved successfully to {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving DataFrame '{df_name}' to {file_path}: {e}\")\n",
    "\n",
    "\n",
    "save_dfs_as_parquet_with_names([patent_info_joined_df, cpc_df, cpc_section_df, cpc_group_df,cpc_subclass_df, cpc_class_df, joined_df_inventor, applicant_df_dropped], \"preprocessed_data\", \n",
    "                               [\"patent_info\", \"cpc_info\", \"cpc_section\", \"cpc_group\", \"cpc_subclass\", \"cpc_class\", \"inventor_info\", \"applicant_info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fbcc6d-725b-4a2e-a350-bc57689a5f16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
